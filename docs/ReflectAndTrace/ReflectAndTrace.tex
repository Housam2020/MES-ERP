\documentclass{article}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{hyperref}

\title{Reflection and Traceability Report on \progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle


\section{Changes in Response to Feedback}

\subsection{Changes in Response to Usability Testing}
The results concluded from the usability testing were thoroughly analyzed and taken into consideration when adding new changes to the final product. Various points of improvement were taken note of as well as numerous key changes to be made. These results can be seen in the \href{docs/UsabilityTesting/UsabilityTesting.pdf}{Usability Testing document}.
\subsection{SRS and Hazard Analysis}

\subsubsection{Changes Made to the SRS}
\begin{enumerate}
    \item \textbf{Added diagrams} \\
    \textit{Why?} To provide visual representations of complex processes, increase clarity, and stay consistent with the rest of the documentation standards.

    \item \textbf{Fixed spelling} \\
    \textit{Why?} To maintain professionalism, ensure correctness, and keep the document free of typographical errors.

    \item \textbf{Added references} \\
    \textit{Why?} To align with formal SRS practices, give credit to external sources where applicable, and enhance document credibility.

    \item \textbf{Added Reflection} \\
    \textit{Why?} To evaluate and discuss key decisions and modifications, ensuring transparency and consistency with reflective sections in similar documents.

    \item \textbf{Looked over the missing context in part 7} \\
    \textit{Why?} To fill gaps and ensure that all sections have the necessary background and details for clarity.

    \item \textbf{Rationales were looked over but no citations were used (hence no citations were added)} \\
    \textit{Why?} The rationales were internally based, and no external sources were needed, so citations were not applicable.

    \item \textbf{Fixed table formatting} \\
    \textit{Why?} To ensure uniform presentation across the document and improve readability and consistency.

    \item \textbf{Added additional context to unclear sections} \\
    \textit{Why?} To clarify ambiguities, make the requirements more precise, and maintain cohesion with the overall web application focus.

    \item \textbf{Removed solution-based requirements} \\
    \textit{Why?} To keep the SRS strictly requirement-focused, ensuring it does not prescribe specific implementations and remains consistent with standard SRS principles.

    \item \textbf{Updated all requirements based on comments and feedback from rubrics} \\
    \textit{Why?} To address identified issues, remain compliant with rubric standards, and ensure the SRS meets its intended quality and completeness.
\end{enumerate}


\subsubsection{Changes Made to the Hazard Analysis}

The document has been thoroughly revised to address feedback from a rubric. Here are the key changes:

\subsubsection{Document Structure Improvements}
\begin{itemize}
  \item Added Table of Contents, List of Tables, and List of Figures
  \item Improved document organization with appropriate page breaks
  \item Updated revision history table with current changes
  \item Added proper labels to Safety/Security Requirements (SSR-1, SSR-2, SSR-3)
\end{itemize}

\subsubsection{Content Enhancements}
\begin{enumerate}
  \item \textbf{Introduction \& Scope}:
  \begin{itemize}
    \item Refined hazard definitions specifically for MES-ERP financial operations
    \item Expanded scope to clearly include all system components (frontend, backend, database, auth)
    \item Added clearer document roadmap
  \end{itemize}

  \item \textbf{System Boundaries \& Components}:
  \begin{itemize}
    \item Added technology specifics (Supabase/PostgreSQL, Next.js/React)
    \item Enhanced hazard descriptions with concrete examples
    \item Added new hazards (race conditions, XSS vulnerabilities, session hijacking)
  \end{itemize}

  \item \textbf{Critical Assumptions}:
  \begin{itemize}
    \item Clarified existing assumptions
    \item Added a fifth assumption about security of underlying infrastructure
  \end{itemize}

  \item \textbf{FMEA Implementation}:
  \begin{itemize}
    \item Created a complete FMEA table with severity, occurrence, and detection ratings
    \item Calculated Risk Priority Numbers (RPN)
    \item Added specific mitigation strategies for each failure mode
    \item Cross-referenced Safety/Security Requirements
  \end{itemize}

  \item \textbf{Safety Requirements}:
  \begin{itemize}
    \item Added formal labels and improved descriptions
    \item Enhanced rationales for implementation
  \end{itemize}

  \item \textbf{Roadmap}:
  \begin{itemize}
    \item Improved immediate implementation items with technical specifics
    \item Added cross-references to SSRs
    \item Added new future implementation item (Security Penetration Testing)
  \end{itemize}
\end{enumerate}

\vspace{1em}
The revisions make the document more precise, technically detailed, and better aligned with software engineering best practices for hazard analysis.


All changes were made to address the rubric feedback, with special attention to improving the technical specificity of hazard descriptions, creating a proper FMEA analysis, and ensuring consistent cross-referencing between identified hazards and safety requirements. The revisions significantly enhanced the document's precision and alignment with software engineering best practices for hazard analysis of financial systems.

\subsection{Design and Design Documentation}

The project's design, documented in the Module Guide (MG) and Module Interface Specification (MIS), evolved from the initial plan to the final version. Here’s a comparison focusing on the key changes:

\subsubsection{Module Guide (MG) Changes}

Comparing the early MG draft with the final:

\begin{itemize}
    \item \textbf{Structure Added:} The final MG adopted a formal Hardware-Hiding (HH), Behaviour-Hiding (BH), and Software Decision (SD) layered structure, which was absent or less defined initially.
    \item \textbf{Modules Defined More Clearly:} Initial module names were generic (like "Reimbursement Submission"). The final MG has specific, named modules within the HH/BH/SD layers (e.g., `Database Interaction Layer` (HH), `Expense Submission \& Tracking` (BH), `Data Validation Module` (SD)).
    \item \textbf{Non-Core Items Removed:} Things like CI/CD and Test Automation, initially considered Software Decision modules, were correctly removed from the core architecture in the final MG, recognized as development processes instead.
    \item \textbf{Secrets Detailed:} Initial secrets were vague. The final MG provides specific technical details hidden by each module (e.g., database specifics for {mDB}, notification service details for {mNotify}).
    \item \textbf{Anticipated Changes Refined:} Initial ACs were broad. The final MG makes them more specific (e.g., mentioning OCR for input formats) and links them directly to module secrets. A new AC for `Financial Reporting Formats` was added.
    \item \textbf{Requirement Mapping Updated:} The mapping between requirements (R1, R2, etc.) and modules was updated to reflect the final, specific module names (e.g., R1 now maps clearly to {mUserAuth}).
    \item \textbf{Use Hierarchy Explained:} The final MG added a textual description explaining which modules depend on others, clarifying the dependencies only shown visually before.
\end{itemize}
Essentially, the MG went from a general outline to a specific architectural plan with clearly defined modules, responsibilities, and relationships.

\subsubsection{Module Interface Specification (MIS) Changes}

Comparing the early MIS draft with the final:

\begin{itemize}
    \item \textbf{Modules Aligned with Final MG:} The final MIS details the *actual* modules from the final MG (like {mDB}, {mUserAuth}, {mExpenseSub}, etc.). The old MIS had specifications for modules that were either preliminary, renamed, or didn't make it into the final architecture (like "Disbursement \& Payment Processing", "Integration with Other University Systems").
    \item \textbf{Increased Detail - Syntax:}
        \begin{itemize}
            \item \textbf{Types:} More specific custom types (\texttt{Credentials}, \texttt{ProfileData}, \texttt{BudgetLine}, \texttt{Blob}, \texttt{Timestamp}) were defined in the final MIS, replacing generic terms like \texttt{Object} or \texttt{Array}.
            \item \textbf{Access Programs:} Function signatures became more precise. New functions reflecting the actual implementation were added (e.g., `registerUser`, `signOut`, `getOperatingBudget`, `saveOperatingBudget`). Parameters and return types were specified more accurately.
            \item \textbf{Constants:} Abstract constants in the old MIS became concrete values or more specific definitions (e.g., file types, session timeouts) in the final version.
        \end{itemize}
    \item \textbf{Increased Detail - Semantics:}
        \begin{itemize}
            \item \textbf{State/Environment Vars:} Descriptions became more specific and tied to implementation details (e.g., `dbState` instead of just listing connections; `AuthProvider`, `FileStorageProvider` identified as external dependencies).
            \item \textbf{Assumptions:} More detailed assumptions were listed (A1-A16), often linking to other modules or specific conditions needed for operation.
            \item \textbf{Routine Semantics:} Descriptions of what each function does (Transitions, Pre/Postconditions) became much clearer, including explicit references to calls made to other modules (e.g., {mDB}, {mValidation}).
            \item \textbf{Local Functions Added:} Relevant internal helper functions (like `\_extractAmountFromReceipt`, `\_canApprove`) were identified and included in the final MIS where appropriate.
        \end{itemize}
    \item \textbf{Notation Clarified:} The final MIS explicitly defined notations like `Map(K -> V)`, `Maybe<T>`, etc., which were used in the specifications.
\end{itemize}
In short, the MIS matured from a rough draft with placeholder modules to a detailed technical specification closely matching the final system architecture and implementation details.

\subsection{VnV Plan and Report} % Changed from \section

Comparing the initial Verification and Validation (VnV) Plan with the final version and the activities documented in the final VnV Report shows a progression from planning to execution, with refinements along the way.

\subsubsection{VnV Plan Evolution}

The VnV Plan itself underwent refinement:
\begin{itemize}
    \item \textbf{Increased Specificity:} The final plan provided much more detail than the initial draft, particularly in the System Tests section (Section 4). Test cases (Test 1-11) in the final plan have explicit inputs (e.g., specific user roles, form data, filenames, simulated concurrent users) and expected outputs (e.g., specific UI messages, database state changes, performance metrics like <2s response time), whereas the old plan often had placeholders or less detailed descriptions.
    \item \textbf{Added Detail on Verification Methods:} The final plan elaborated significantly on how the SRS and Design documents would be verified (Section 2.2, 2.3), explicitly mentioning peer reviews, stakeholder involvement, supervisor feedback, and the use of checklists from the repository. It also added sections for Implementation Verification (Section 2.5) and Software Validation (Section 2.7), outlining specific approaches like code reviews, static analysis, test execution strategies, external data validation, and User Acceptance Testing (UAT).
    \item \textbf{Tooling Specification:} The final plan (Section 2.6) explicitly listed the chosen automated tools (Jest, React Testing Library, ESLint, Prettier, GitHub Actions, Lighthouse, npm audit), whereas the old plan mentioned tools more generally. The final plan also specified the 90\% test coverage goal and how it would be tracked via CI.
    \item \textbf{Usability Test Details:} The final plan added a concrete Appendix A with sample usability survey questions, making the planned usability testing (an "Extra") much more specific than the brief mention in the old plan.
    \item \textbf{Clarification of Scope:} The final plan refined the unit testing scope (Section 5.2), clarifying what was in/out of scope (e.g., mocking third-party libraries).
    \item \textbf{Refinement of Plan Verification:} The approach to verifying the VnV plan itself was clarified, focusing on peer/supervisor review and checklists rather than the initially mentioned "Mutation Testing" of the plan, which was re-scoped to inform test case design instead.
\end{itemize}
The plan matured from a template outlining general V\&V activities to a detailed, actionable strategy specifying tools, techniques, and concrete test descriptions.

\subsubsection{VnV Execution vs. Final Plan (Comparison with VnV Report)}

The VnV Report documents the execution of the activities laid out in the final VnV Plan:
\begin{itemize}
    \item \textbf{Test Execution and Reporting:} The VnV Report (Sections 1-3) directly addresses the outcomes of the system tests (Test 1-11) defined in the final VnV Plan. It follows the structure of reporting findings, analysis, and code improvements made in response to test results, rather than just re-stating the test procedures. This confirms that the planned system tests were largely executed.
    \item \textbf{Requirement Traceability:} Both the final plan (Table 1) and the report (Table 3 and 4) include traceability matrices mapping tests to requirements, demonstrating follow-through on this verification step. The report's matrix is based on the tests actually performed.
    \item \textbf{Unit Testing:} The VnV Report (Section 5) discusses the unit testing approach using Jest and provides sample test cases, aligning with the philosophy outlined in the final VnV Plan (Section 5). However, the reported code coverage (10-20\% automated) in the report (Section 7) falls significantly short of the 90\% goal mentioned in the final plan's CI section, indicating a deviation in execution likely due to time constraints or complexity. The report acknowledges this and mentions prioritizing critical functionalities.
    \item \textbf{Changes Due to Testing:} The VnV Report (Section 6) explicitly lists bug fixes and enhancements made in response to testing, demonstrating that the V\&V process actively improved the product, as intended by the plan. Examples include fixing attachment handling, duplicate submissions, improving notification reliability, adding UI clarifications, and performance optimizations.
    \item \textbf{Automated Testing \& CI/CD:} The report (Section 8) confirms the use of the automated tools (Jest, ESLint, Prettier, GitHub Actions) and CI workflows specified in the final plan (Section 2.6).
    \item \textbf{Usability Testing:} The report (Section 3.1 and 3.5.1) details the results of the usability testing described as an "Extra" in the plan (Section 1.3) and Appendix A, confirming this planned activity was executed.
\end{itemize}
Overall, the VnV Report demonstrates that the team attempted to execute the refined VnV Plan. While system tests and usability tests appear to have been carried out as planned, the major deviation was the significantly lower-than-planned automated unit test coverage. The report reflects honestly on the testing performed and the resulting improvements.

\section{Challenge Level and Extras}

\subsection{Challenge Level: General}
The general challenge level comes from the integration of several complex components: a multi-group RBAC system, database interactions for real-time budget/request tracking, form handling with file uploads and OCR, automated notifications, and data visualization, all within a modern web framework. Ensuring data consistency, security, and a usable interface across different user roles presents a significant challenge. This must be done while maintaining stability and performance.

\subsection{Extras}
\begin{enumerate}
\item \textbf{Usability Testing} \
Conducted formal usability testing with 8 stakeholders (4 student leaders, 2 MES administrators, and 2 regular club members) to evaluate platform usability. Testing was performed remotely via screen sharing using a think-aloud protocol, with participants completing four core tasks: submitting a reimbursement request, tracking request status, approving requests (administrators only), and updating account information. Both quantitative metrics (task completion rates, time, ease-of-use ratings) and qualitative feedback were collected. The testing achieved an overall 96.9\% task completion rate with an average satisfaction score of 4.3/5. Key improvements implemented based on testing results included enhanced OCR feedback, improved payment method interface clarity, and identification of future enhancements for form layout optimization.
\item \textbf{User Documentation} \
Created comprehensive user documentation in the form of written guides and video tutorials that guide end-users through key tasks like submitting requests, managing budgets (for admins), and navigating the platform. This documentation serves different user roles within the system and provides step-by-step instructions for all critical workflows.
\item \textbf{User Guide Page} \
Implemented a dedicated help section directly within the application to provide contextual assistance and guidance for users as they navigate through different features of the platform. This integrated support system helps users understand complex processes and reduces the learning curve for new users.
\item \textbf{Demo/Instructional Video} \
Developed a comprehensive video demonstration of the system's functionality that serves both as a promotional tool and an instructional guide for new users to understand the workflow and features of the MES-ERP platform. The video covers all major user journeys and highlights the efficiency gains compared to the previous manual process.
\end{enumerate}

\section{Design Iteration (LO11 (PrototypeIterate))}

The development of MES-ERP followed an iterative process, evolving significantly from the initial concept outlined in the Problem Statement to the final demonstrated product.

\begin{enumerate}
    \item \textbf{Initial Concept \& POC Planning:} The project began with the core goal of replacing the MES's manual spreadsheet/form-based system with a digital platform for reimbursement requests and budget tracking. The initial Proof of Concept (POC) plan, as described in the Development Plan and POC Team Contributions, focused on demonstrating the fundamental feasibility:
        \begin{itemize}
            \item Basic user authentication (login/register).
            \item A minimal request submission form for users.
            \item A basic admin dashboard to view submitted requests and update their status.
        \end{itemize}
        This stage aimed to mitigate the primary risk identified: handling diverse inputs (receipts) and establishing a working user-admin interaction loop.

    \item \textbf{Post-POC Refinement (Towards Rev 0):} Based on the successful POC, the design expanded significantly for Revision 0. Key developments likely included:
        \begin{itemize}
            \item \textbf{RBAC Implementation:} The necessity of handling multiple clubs and user roles became apparent. The design iterated from a potentially simpler model to the more complex multi-group RBAC system using junction tables (\texttt{user\_roles}, \texttt{group\_roles}, \texttt{role\_permissions}). This was a major design iteration driven by accurately modeling the MES structure.
            \item \textbf{Core Feature Expansion:} Functionality beyond basic requests was added, including modules for managing Users, Roles, and Groups, as reflected in the Rev 0 Demo Plan and the final dashboard structure.
            \item \textbf{Budget Management:} Initial concepts for budget tracking likely evolved into the more structured \texttt{operating\_budget\_lines} approach seen in the final implementation, allowing detailed income/expense tracking per group.
            \item \textbf{Analytics Introduction:} Basic analytics visualizations were introduced (\texttt{/dashboard/analytics}), demonstrating the potential for data-driven insights.
            \item \textbf{Early OCR Integration:} Receipt scanning/OCR, initially a stretch goal, appears to have been incorporated by Rev 0, likely using Tesseract.js as integrated into the Reimbursement Form component.
        \end{itemize}
        Feedback from stakeholder reviews (planned in the SRS/VnV Plan verification steps) and supervisor meetings likely influenced the prioritization and refinement of these features.

    \item \textbf{Revision 0 Feedback and Final Iteration (Towards Rev 1):} The Rev 0 demonstration served as a key validation point. Feedback from this demo, along with ongoing development and testing (as documented in the VnV Report), drove the final iteration:
        \begin{itemize}
            \item \textbf{Refinement based on Testing:} Bug fixes identified during V\&V (e.g., handling missing attachments, duplicate submissions, notification failures for invalid emails, UTC timestamp standardization) led to direct code changes and improvements in error handling and validation logic (\texttt{M\ref{mValidation}}, \texttt{M\ref{mNotify}}).
            \item \textbf{Usability Improvements:} Informal user testing and feedback (part of the "Extras") led to UI refinements like clearer labels, tooltips, and success messages (\texttt{M\ref{mGUI}}). The refactoring of the Reimbursement Form into smaller components (\texttt{src/components/reimbursement/}) was likely done during this phase to improve maintainability and user experience.
            \item \textbf{Performance Optimization:} Performance bottlenecks identified under load (Test 7, Test 9) prompted optimizations like database indexing and caching.
            \item \textbf{RBAC Polish:} The logic for assigning and managing roles, especially differentiating between global and group-specific roles and handling permissions correctly in the Users/Roles management pages, likely underwent refinement based on testing and implementation challenges.
            \item \textbf{Documentation Completion:} The User Guide and final V\&V Report were created, reflecting the finalized feature set.
        \end{itemize}

    \item \textbf{Final Design:} The final design reflects this iterative refinement. The modular structure (MG/MIS) provided a framework, but the specific implementation details, particularly for RBAC, budget management, and the reimbursement form's complexity (including OCR), evolved based on tackling requirements, incorporating feedback, and addressing issues found during testing. The decision to integrate OCR early, despite being a stretch goal, likely came from recognizing its high potential value for users. The V\&V process proved crucial in identifying and correcting functional bugs, performance issues, and usability gaps before the final demonstration.
\end{enumerate}

\section{Design Decisions (LO12)}


Our design process aimed to create a robust, maintainable, and secure platform tailored to the MES's specific needs, while working within the constraints of a capstone project. Key decisions included:

\begin{itemize}
    \item \textbf{Technology Stack (Next.js, TypeScript, Supabase):}
        The choice of Next.js and TypeScript was initially guided by supervisor constraints for consistency with other MES projects, as noted in the Development Plan. However, this stack proved advantageous. Next.js provided a powerful framework for both frontend (React) and backend (API Routes), simplifying development. TypeScript offered static typing, crucial for catching errors early in a complex application involving financial data and intricate permissions. Supabase was selected as the Backend-as-a-Service (BaaS) platform. This significantly reduced the backend development overhead (database setup, authentication management, storage) allowing the team to focus on core application logic, fitting well within the project's time and budget constraints. The trade-off was a dependency on Supabase's infrastructure and potential limitations of its free/pro tiers.

    \item \textbf{Modular Architecture (Information Hiding - MG/MIS):}
        We adopted the principles of information hiding, decomposing the system into Hardware-Hiding (Database Interaction), Behaviour-Hiding (Core Features like Expense Submission, Approval Workflow), and Software Decision (Validation, GUI) modules, as documented in the Module Guide (MG) and specified in the Module Interface Specification (MIS). This decision was driven by the need for maintainability and adaptability. Anticipated changes, such as supporting new input formats or notification methods, were encapsulated as module secrets, aiming to localize the impact of future modifications. This structured approach, while requiring upfront design effort, was deemed essential for a system intended for long-term use by the MES.

    \item \textbf{Role-Based Access Control (RBAC) Implementation:}
        The decision to implement a relatively complex RBAC system, supporting users belonging to multiple groups with potentially different roles in each, stemmed directly from the MES's organizational structure (many clubs with varying leadership roles). A simpler model (e.g., one user, one role) would not have accurately reflected the real-world requirements. We used junction tables (\texttt{user\_roles}, \texttt{group\_roles}, \texttt{role\_permissions}) in the database schema, a standard approach for modeling these many-to-many relationships. This design provided the necessary flexibility but increased implementation complexity, particularly in permission checking logic within the middleware, API routes, and frontend components (\texttt{usePermissions} hook). This complexity was a necessary trade-off for accurately modeling the domain.

    \item \textbf{Database Schema Design:}
        The schema, documented in \texttt{src/docs/DATABASE.md}, prioritized clear relationships between entities (users, groups, roles, requests, budgets). The use of junction tables for RBAC was crucial. The \texttt{operating\_budget\_lines} table provided a flexible structure for managing detailed budgets per group, separating allocated amounts from actual expenses derived from \texttt{payment\_requests}. This separation supported accurate tracking and reporting.

    \item \textbf{API Route Structure:}
        We utilized Next.js API routes for specific backend operations like sending notifications (\texttt{send-email-notif}, \texttt{send-sms-notif}) and updating user roles/groups (\texttt{update-role}, \texttt{update-group}). This kept backend logic separate from the frontend rendering, promoting cleaner code and easier testing of backend functionality.

    \item \textbf{External Service Integration (SendGrid, Tesseract.js):}
        Integrating external services like SendGrid for email notifications and Tesseract.js for OCR simplified development compared to building these features from scratch. This aligned with the project's constraints, allowing focus on core MES-specific workflows. The limitation is reliance on these services' availability and potential costs.

    \item \textbf{Assumption/Limitation Impact:}
        The assumption of reliable internet meant little effort was put into offline capabilities. The budget constraint influenced the choice of Supabase (generous free tier) and limited the scope of "stretch goals". The capstone timeline necessitated prioritizing core features over extensive performance optimization or advanced features like ML-based categorization initially. The design explicitly tried to accommodate anticipated changes (like reporting formats) by isolating related logic in specific modules.
\end{itemize}

Overall, design decisions prioritized fulfilling core MES requirements, ensuring security and data integrity for financial operations, and promoting maintainability, while leveraging existing tools and services to meet project constraints.


\section{Economic Considerations (LO23)}


As a capstone project developed specifically for the McMaster Engineering Society (MES), the initial "market" is internal. However, the underlying problem – managing finances for multiple student clubs within a larger organization – is common across universities.

\begin{itemize}
    \item \textbf{Market Potential:}
        \begin{itemize}
            \item \textbf{Internal (MES):} The immediate user base consists of roughly 60 MES-affiliated clubs, MES executives, and financial administrators. Success here relies on adoption and usability.
            \item \textbf{McMaster Expansion:} Other student societies within McMaster (e.g., MSU clubs, Faculty societies) face similar challenges and could be potential users if the platform is adaptable.
            \item \textbf{External Universities:} Student unions/societies at other universities represent a larger potential market, though adaptation to different financial policies would be necessary.
        \end{itemize}

    \item \textbf{Marketing and User Attraction:}
        \begin{itemize}
            \item \textbf{MES Internal:} Promotion via MES communication channels, training sessions for club treasurers, and endorsements from MES executives. Ease of use and clear benefits over the old system (faster reimbursements, better tracking) are key selling points.
            \item \textbf{External/Open Source:} If generalized or open-sourced, marketing could involve presentations at student government conferences, articles in university tech forums, presence on GitHub, and potentially partnerships with university IT departments. Attracting users would depend on demonstrating clear advantages over generic tools (like spreadsheets) or commercial alternatives, ease of deployment, and good documentation.
        \end{itemize}

    \item \textbf{Production and Ongoing Costs:}
        \begin{itemize}
            \item \textbf{Initial Development Cost:} Primarily student labor within the capstone structure. The stated project budget was \$750, likely covering minor expenses (perhaps specific software tools or small service tiers). Estimating a commercial equivalent would involve multiplying development hours (estimated 400-500 in the VnV Report) by a junior/intermediate developer rate, resulting in tens of thousands of dollars.
            \item \textbf{Hosting \& Services:} Supabase offers a free tier, but scaling might require paid plans (\$25+/month). Vercel (for Next.js hosting) also has free/pro tiers. SendGrid and Twilio have usage-based pricing, likely low initially but scaling with notification volume. Domain name registration (around \$15/year). Total ongoing costs could range from \$0 (on free tiers with low usage) to \$50-\$100+/month depending on scale and features used.
            \item \textbf{Maintenance:} Requires ongoing effort for bug fixes, security updates, adapting to policy changes, and user support. This could be handled by future student volunteers, MES IT staff, or potentially paid contractors, representing a significant hidden cost.
        \end{itemize}

    \item \textbf{Pricing Model (If Commercialized/Generalized):}
        \begin{itemize}
            \item \textbf{Subscription:} A tiered annual subscription based on the number of clubs or users seems most plausible for university societies (e.g., \$500-\$2000/year per society).
            \item \textbf{Open Source + Support:} Offer the core platform as open source, charging for setup assistance, hosting, custom modifications, or premium support contracts.
        \end{itemize}

    \item \textbf{Sales Estimate / Break-Even:}
        Assuming ongoing costs of \$600/year (\$50/month) and needing to recoup an estimated \$30,000 commercial development cost over 3 years (\$10,000/year), the platform would need to generate \$10,600 annually. At a \$1000/year subscription, this requires roughly 11 paying student societies. Given the niche market, achieving significant profit seems challenging without broad adoption or a very lean maintenance model.

    \item \textbf{Potential Users:} Initially ~60 MES clubs + MES staff. Potentially hundreds of clubs within McMaster. Thousands across Canadian universities.
\end{itemize}

In conclusion, while MES-ERP addresses a real need for MES, its direct commercial viability is uncertain due to the niche market and the likely need for customization for other institutions. An open-source model with optional paid support or focusing on adoption within McMaster might be more realistic paths for broader impact beyond the initial MES deployment. The primary economic benefit for MES is the significant saving in administrative time and improved financial control compared to the previous manual system.

\section{Reflection on Project Management (LO24)}


\subsection{How Does Your Project Management Compare to Your Development Plan}

Our project management generally followed the Development Plan, but with some natural adaptations:

\begin{itemize}
    \item \textbf{Team Meeting Plan:} We adhered to the plan for regular team meetings (twice weekly initially, likely adjusting frequency later) and scheduled supervisor meetings (though one was missed by a member). Attendance, as tracked in contribution reports, was generally high for team meetings.
    \item \textbf{Team Communication Plan:} Discord was used as the primary informal communication channel, as planned. GitHub Issues were used for tracking tasks and feedback, although perhaps not as consistently for \textit{all} communication or discussion as initially intended. Merge conflicts and urgent issues were likely handled via Discord/calls.
    \item \textbf{Team Member Roles:} Initial roles (Meeting Chair, Notetaker, Reviewer, Leader, Helper) were defined. In practice, roles in small student teams often become more fluid, with members contributing across different areas based on need and expertise. The commit history suggests varying levels of contribution, which might indicate roles shifted or workloads weren't perfectly balanced despite the initial plan. The plan did include monthly reviews to adjust roles, but it's unclear if these formal reviews occurred.
    \item \textbf{Workflow Plan (Git, Issues, CI/CD):}
        \begin{itemize}
            \item \textbf{Git Usage:} The use of branches for features/bugfixes and Pull Requests (PRs) with peer review seems to have been implemented, based on standard practice and the presence of multiple contributors. Commit messages aimed for descriptiveness (mentioning Conventional Commits). Tags for releases may or may not have been consistently used.
            \item \textbf{Issue Management:} GitHub Issues were used, and templates were defined. The team contribution reports mention issues authored and assigned, indicating usage. The effectiveness depended on issue granularity and consistent tracking/closing.
            \item \textbf{CI/CD Implementation:} The planned CI/CD pipeline (Lint, Format, PDF Build, Unit Tests via GitHub Actions) was successfully implemented, as evidenced by the workflow files. This automated quality checks and documentation builds. Test coverage goals (90\%) were set, but the VnV report indicates actual automated coverage was lower, suggesting challenges in achieving this target.
        \end{itemize}
    \item \textbf{Technology:} The core technology stack (Next.js, TypeScript, Supabase, Shadcn UI, Tailwind, Jest) defined in the Development Plan was indeed used in the implementation.
\end{itemize}

\subsection{What Went Well?}

\begin{itemize}
  \item \textbf{Clear Initial Planning:} The Development Plan provided a good roadmap for roles, communication, and workflow.
  \item \textbf{Technology Stack Adoption:} The team successfully implemented the application using the chosen modern web technologies.
  \item \textbf{Version Control:} Effective use of Git and GitHub facilitated collaboration, code sharing, and tracking changes.
  \item \textbf{CI/CD Automation:} Implementing workflows for linting, formatting, testing, and PDF building automated crucial quality checks and saved manual effort.
  \item \textbf{Communication Channels:} Utilizing Discord for quick communication and GitHub Issues for task tracking generally worked well.
  \item \textbf{Regular Meetings:} Consistent team meetings helped maintain alignment and address roadblocks.
\end{itemize}

\subsection{What Went Wrong?}

\begin{itemize}
  \item \textbf{Achieving Test Coverage Goals:} The ambitious 90\% automated test coverage target was not met, indicating challenges in writing comprehensive tests alongside feature development, possibly due to time constraints or complexity.
  \item \textbf{Initial Setup Friction:} Reflections mentioned initial difficulties with setting up development environments (e.g., LaTeX), causing early delays.
  \item \textbf{Strict Role Adherence:} Maintaining the initially defined, distinct roles might have been impractical; tasks likely required more cross-functional collaboration than the roles implied.
  \item \textbf{Meeting Scheduling:} Some scheduling conflicts occurred, leading to missed supervisor meetings or team building activities.
  \item \textbf{Issue Tracker Discipline:} While used, the consistency of using GitHub Issues for \textit{all} task tracking and discussion might have varied.
\end{itemize}

\subsection{What Would you Do Differently Next Time?}

\begin{itemize}
  \item \textbf{Proactive Workload Management:} Implement more explicit task breakdown and assignment during sprint planning. Use pair programming or focused work sessions to help members who might be falling behind or need assistance. Regularly check in on individual progress and offer support.
  \item \textbf{Integrate Testing Earlier and Continuously:} Write unit tests concurrently with feature development rather than potentially leaving it towards the end. Set more realistic, incremental coverage goals throughout the project lifecycle.
  \item \textbf{Improve Onboarding/Setup:} Create a more streamlined setup guide or utilize tools like Dev Containers to minimize initial environment configuration issues.
  \item \textbf{Flexible Roles:} Define roles more flexibly from the start, acknowledging that members will likely contribute across different areas. Emphasize shared responsibility.
  \item \textbf{Enhanced Issue Tracking:} Encourage more disciplined use of the issue tracker for all tasks, discussions, and decisions to improve traceability and transparency.
  \item \textbf{Better Time Estimation:} Factor in more buffer time for complex features (like RBAC) and for writing thorough tests.
\end{itemize}

\section{Reflection on Capstone}

Throughout the duration of the capstone, we gained valuable experience in several key areas. We improved our project management skills by organizing and prioritizing tasks effectively, ensuring deadlines were met, and coordinating with team members. Our coding abilities expanded as we learned to apply software engineering principles to real-world problems. Teamwork and collaboration became critical, as we frequently had to communicate with others, delegate responsibilities, and integrate diverse skill sets into a unified product. Additionally, reflecting on each stage of the project helped us develop critical thinking skills, making it easier to identify and resolve issues early on. Finally, we grew more confident in working with external teams, stakeholders, and mentors, which taught us to remain consistent with the established design processes and maintain clear, structured communication.

\subsection{Which Courses Were Relevant}

Several courses directly informed our approach to this project. For instance, Databases proved essential for designing and maintaining efficient data storage, while Software Architecture and Software Design helped us structure the system in a modular and scalable way. Software Testing guided us in writing test suites and performing systematic debugging, ensuring reliable functionality. Computer Interfaces provided insights into user experience considerations, which was valuable for front-end design and usability testing. Finally, the Engineering Design courses taught us to follow a structured design process, from requirement gathering to implementation and validation.

\subsection{Knowledge/Skills Outside of Courses}


Beyond the formal coursework, we had to develop additional project management skills such as scheduling, risk assessment, and resource allocation. We also needed to improve our web development capabilities, particularly in frameworks and libraries not covered in class. Another area of growth was image processing and algorithms, including crafting and optimizing regular expressions for data validation and analysis. Moreover, we honed our soft skills, from effective communication and negotiation to conflict resolution and team coordination, all of which proved vital for successful collaboration and stakeholder engagement throughout the project.


\end{document}